{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写一篇小红书文案, 关于一人公司<|assistant|>的求职攻略\n",
      "\n",
      "标题：🌈✨ 一职难求，但一个人公司的就业之路！🔥💼\n",
      "\n",
      "正文：\n",
      "亲爱的小伙伴们，今天我来给大家分享一个我在工作中发现的一个有趣的小秘密——一个人公司。你可能不知道，一个人公司不仅能让你找到工作，还能让你在职场上更加自由和自在。\n",
      "\n",
      "首先，我想说的是，一个人公司的优势远不止于此。它让你有更多的时间去享受生活，因为没有团队压力，你可以更专注于自己的事情。而且\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name='Qwen/Qwen2.5-0.5B-Instruct'\n",
    "\n",
    "device=torch.device('cpu')\n",
    "\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "  model_name,\n",
    "  device_map={\"\": device},\n",
    "  # torch_dtype='auto',\n",
    "  torch_dtype=torch.float16,\n",
    "  # trust_remote_code=True,\n",
    "  low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "prompt='写一篇小红书文案, 关于一人公司<|assistant|>'\n",
    "\n",
    "# tokenize input prompt\n",
    "input_ids=tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "# gen text\n",
    "gen_output=model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=100\n",
    ")\n",
    "\n",
    "# print(gen_output)\n",
    "\n",
    "print(tokenizer.decode(gen_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14990,    11,   879,   525,   498]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# device=torch.device('mps')\n",
    "device=torch.device('cpu')\n",
    "tokenizer=AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')\n",
    "\n",
    "prompt='hello, who are you'\n",
    "\n",
    "input_ids=tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(101, device='mps:0') [CLS]\n",
      "tensor(7592, device='mps:0') hello\n",
      "tensor(2088, device='mps:0') world\n",
      "tensor(102, device='mps:0') [SEP]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Set proxy\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:1087'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:1087'\n",
    "\n",
    "embed_model='nomic-ai/nomic-embed-text-v1.5'\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(embed_model)\n",
    "\n",
    "# prompt='写一篇小红书文案, 关于一人公司<|assistant|>'\n",
    "prompt='hello world'\n",
    "input_ids=tokenizer(prompt, return_tensors='pt').input_ids.to('mps')\n",
    "# print(input_ids)\n",
    "\n",
    "# see each token\n",
    "for id in input_ids[0]:\n",
    "  print(id, tokenizer.decode(id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0028, -6.5665,  1.8038,  ...,  5.9021, -2.5729,  5.6168],\n",
      "         [-0.3730, -6.3617, -3.1002,  ...,  4.3737, -2.5950,  7.9185],\n",
      "         [ 1.3865, -1.9655, -1.4372,  ...,  2.7270,  2.2920,  2.4780]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tokens:  {'input_ids': tensor([[ 101, 7592,  102]]), 'token_type_ids': tensor([[0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# contextual word embedding\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "embed_model='nomic-ai/nomic-embed-text-v1.5'\n",
    "model_name='Qwen/Qwen2.5-0.5B-Instruct'\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(embed_model)\n",
    "\n",
    "model=AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tokenize sentence\n",
    "tokens=tokenizer('hello', return_tensors='pt')\n",
    "\n",
    "output=model(**tokens)[0]\n",
    "\n",
    "print(output)\n",
    "\n",
    "print('tokens: ', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.4600, -0.0252, -0.0795,  ..., -0.1862, -0.3723, -0.0297],\n",
      "         [-0.2925,  0.7294,  0.5701,  ..., -0.2953, -0.2545, -0.2009],\n",
      "         [-1.0567,  0.5812, -0.4387,  ...,  0.3261, -0.8292,  0.8170],\n",
      "         ...,\n",
      "         [ 0.5983,  0.2496,  0.0620,  ...,  1.0276, -0.7775, -0.7397],\n",
      "         [-1.1675, -0.1209,  0.0104,  ...,  0.6969, -0.1156, -0.5755],\n",
      "         [-3.2867, -0.0255,  0.0604,  ..., -0.2898, -0.1752, -0.1026]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "output shape:  torch.Size([1, 9, 384])\n"
     ]
    }
   ],
   "source": [
    "# use microsoft/deberta model\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "embed_model='microsoft/deberta-base'\n",
    "model_name='microsoft/deberta-v3-xsmall'\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(embed_model)\n",
    "\n",
    "model=AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# tokenize sentence\n",
    "tokens=tokenizer(\"hello, what's your name?\", return_tensors='pt')\n",
    "\n",
    "output=model(**tokens)[0]\n",
    "\n",
    "print(output)\n",
    "\n",
    "print('output shape: ', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.01118244e-01  6.21917145e-03 -5.31980842e-02 -3.73656233e-03\n",
      " -4.93359007e-02  7.06774965e-02  9.81120765e-03 -6.60492200e-03\n",
      "  1.02338508e-01 -3.96541581e-02 -4.90543470e-02  6.84917942e-02\n",
      "  1.52453668e-02  6.61561489e-02 -4.10934500e-02  7.48507529e-02\n",
      "  3.59498858e-02 -4.57872041e-02  4.98377299e-03 -1.02802239e-01\n",
      " -2.28543431e-02  2.00467352e-02  1.60432365e-02  2.29911208e-02\n",
      " -5.77333309e-02  6.32299259e-02 -7.45138386e-03  1.58397670e-04\n",
      " -1.20708048e-01 -1.80868208e-02  2.48436797e-02  3.47675243e-03\n",
      " -5.60263135e-02  6.32715470e-04 -2.15360988e-02 -5.32185426e-03\n",
      " -1.17753586e-02 -5.05840965e-02 -2.54806317e-02 -2.82878876e-02\n",
      " -1.00786716e-01 -5.71530648e-02  2.63541080e-02 -1.95630044e-02\n",
      "  9.32950005e-02 -6.16598912e-02 -8.21805838e-03 -1.23697044e-02\n",
      "  6.45528510e-02  5.62597141e-02 -5.23218066e-02  5.20572923e-02\n",
      "  1.29822977e-02  3.79677191e-02  6.79668561e-02  2.24372605e-03\n",
      " -7.05436617e-02 -9.18390602e-02  9.04516596e-03 -3.44583616e-02\n",
      " -4.47851196e-02  5.45186363e-03  3.17533538e-02 -9.07040946e-03\n",
      "  1.13690078e-01 -2.33851522e-02  4.52833697e-02  5.71815148e-02\n",
      " -3.85731347e-02  5.79074211e-02 -8.69215727e-02  6.16689064e-02\n",
      "  2.82864645e-02 -2.10059304e-02  3.10940966e-02 -3.27125639e-02\n",
      "  4.67248494e-03  4.78216540e-03 -1.93228107e-02 -2.86192093e-02\n",
      "  7.52142956e-03 -1.13710560e-01 -8.34770054e-02  4.19954099e-02\n",
      "  1.94296725e-02 -2.82414164e-02  6.47691041e-02  2.08627433e-02\n",
      " -1.05840899e-02  3.98121849e-02 -5.06563596e-02 -3.59860994e-02\n",
      " -3.04985438e-02  7.26287365e-02  8.52930639e-03  7.40728050e-04\n",
      " -1.15616424e-02 -4.89361323e-02 -4.60212044e-02  7.55543858e-02\n",
      "  2.99104955e-02 -7.26501420e-02 -1.86700076e-02 -6.25837743e-02\n",
      "  1.15245387e-01 -2.74320506e-02  1.42706335e-01 -4.73503629e-03\n",
      "  2.79690456e-02 -2.86769420e-02 -2.90926564e-02 -4.90569584e-02\n",
      "  5.38246557e-02  9.05398801e-02 -4.86399571e-04 -5.50927781e-02\n",
      "  9.43470076e-02  2.76530683e-02 -3.42085846e-02 -3.43846902e-02\n",
      "  3.06892339e-02  8.77467096e-02  2.80492310e-03  5.69470879e-03\n",
      " -6.50486648e-02 -4.85246107e-02  1.24811999e-01 -2.00433138e-33\n",
      " -9.46430042e-02 -2.24543530e-02  3.13926004e-02 -1.88450085e-03\n",
      "  3.31173800e-02  4.53642979e-02 -5.79040824e-03  1.80036444e-02\n",
      " -5.35182878e-02  2.96915956e-02 -8.41415152e-02 -5.78119047e-02\n",
      " -6.27788305e-02 -6.69236332e-02  8.71710032e-02  4.92126681e-02\n",
      " -1.04315681e-02  5.47597110e-02  1.81650985e-02 -5.96557856e-02\n",
      " -5.63401729e-02  7.40653202e-02 -6.57316893e-02 -4.00084443e-03\n",
      " -4.91656661e-02  2.20304215e-03  1.59439370e-02 -2.69750468e-02\n",
      "  6.22361898e-02  3.06858718e-02  7.88181350e-02 -2.10954100e-02\n",
      " -8.20396375e-03 -3.90137546e-03  6.92315772e-02 -3.79824489e-02\n",
      " -5.40203638e-02  3.08493003e-02 -1.55238882e-02  4.25886959e-02\n",
      "  1.09350514e-02  4.28452045e-02 -7.30435029e-02  5.30742109e-02\n",
      "  3.91231030e-02  6.35186508e-02  9.96625330e-03  5.45612834e-02\n",
      "  2.86654592e-03  6.17573522e-02 -2.25946913e-03 -6.89983219e-02\n",
      " -2.76408531e-02 -4.10608314e-02 -3.45717967e-02  3.49036120e-02\n",
      "  2.96471044e-02 -2.96483352e-03  2.10023839e-02 -3.45090553e-02\n",
      " -4.72447276e-02  6.25732169e-02 -1.50209442e-02 -3.45555623e-03\n",
      "  5.38817188e-03  3.84821510e-03  2.18700264e-02 -5.80254709e-03\n",
      " -2.37194020e-02 -1.16038751e-02 -5.45560382e-02  5.42483553e-02\n",
      "  4.65983264e-02 -8.74197260e-02  2.20385492e-02 -4.61031543e-03\n",
      "  1.43364193e-02  2.85083614e-02 -8.20252672e-02 -4.98594306e-02\n",
      " -6.79289773e-02  7.31571093e-02  2.18230020e-02 -5.00749461e-02\n",
      "  8.26647133e-02  1.01304147e-02 -4.16842550e-02 -1.12509385e-01\n",
      " -1.42058218e-02  4.21115533e-02 -1.77038703e-02 -6.79577217e-02\n",
      "  1.02039963e-01 -3.40815149e-02 -3.74897122e-02  2.03663653e-33\n",
      "  4.45371084e-02 -7.73091242e-02  8.57999623e-02  5.39102331e-02\n",
      "  2.45041251e-02 -1.09596271e-02 -1.39118820e-01  2.35081371e-02\n",
      "  3.23505662e-02  4.76621874e-02  1.58999711e-02 -1.94903892e-02\n",
      "  1.19805671e-01  8.99807829e-03  1.21436849e-01  3.07378657e-02\n",
      "  8.95614624e-02 -6.60455003e-02  3.11405342e-02 -1.49690798e-02\n",
      "  1.65814217e-02 -3.21118049e-02  8.92064127e-04 -4.99483533e-02\n",
      " -4.33656536e-02  4.66631129e-02 -3.19390856e-02  2.69169807e-02\n",
      " -1.87864397e-02  2.16328669e-02 -2.26962361e-02  3.74644436e-03\n",
      " -3.06734145e-02  5.97713478e-02 -1.66010875e-02  2.26641763e-02\n",
      "  3.32261138e-02 -4.17922437e-02 -3.76826413e-02  2.00037621e-02\n",
      "  2.23105494e-02  3.71804871e-02 -4.85334247e-02  1.28151432e-01\n",
      "  2.43041385e-02 -4.39781211e-02 -2.36686133e-02  5.55922538e-02\n",
      " -5.80870770e-02  1.93278268e-02 -1.24430522e-01  1.18357670e-02\n",
      " -4.85977232e-02 -3.30086313e-02  2.72031464e-02  1.27591081e-02\n",
      " -1.43706789e-02  4.95532677e-02 -2.89294054e-03 -3.23373005e-02\n",
      " -6.97857351e-04 -3.00660897e-02 -1.22033209e-01  3.48615833e-02\n",
      " -9.71477106e-03  3.69019620e-02  1.03178108e-02  6.51522577e-02\n",
      "  9.36479890e-04 -5.40270098e-02 -9.96808708e-02  3.31882760e-03\n",
      " -9.53267440e-02  9.40429717e-02 -2.30122935e-02  2.32247151e-02\n",
      "  2.83039901e-02 -2.08848044e-02  3.65411527e-02 -7.77364522e-03\n",
      " -1.32647380e-02  1.87425893e-02 -1.84267685e-02  3.18986662e-02\n",
      "  2.73884665e-02  6.95071891e-02  8.11898634e-02 -5.23539446e-03\n",
      "  8.20281077e-03  1.19420774e-02 -5.87245217e-03 -2.40443628e-02\n",
      "  5.49864359e-02 -2.57970840e-02 -2.73273811e-02 -1.34853444e-08\n",
      " -1.61785726e-02  3.72488163e-02 -7.40155354e-02 -6.67105317e-02\n",
      " -2.17109434e-02  1.71936769e-02  1.13345543e-02  8.13559070e-02\n",
      "  1.27904303e-02  5.32453619e-02 -1.59634762e-02  5.41942678e-02\n",
      " -2.15939432e-02  1.07520364e-01 -5.63574657e-02  1.16502782e-02\n",
      "  8.82238373e-02 -6.10681362e-02 -7.67373946e-03  2.10414641e-03\n",
      " -3.25326249e-02 -2.98010465e-02  6.86931610e-02 -3.38717829e-03\n",
      " -1.71572622e-02  3.84964347e-02 -2.41862889e-02 -4.65057641e-02\n",
      "  4.00374681e-02  4.73578349e-02  5.19166999e-02 -5.69454208e-03\n",
      " -4.16550040e-02  2.05284413e-02 -3.82023714e-02 -5.84068410e-02\n",
      "  2.77302172e-02 -9.27437656e-03  8.59459937e-02 -4.68000770e-02\n",
      "  1.75446330e-03  1.09177977e-01 -2.13345159e-02 -7.33498037e-02\n",
      "  6.01142384e-02  4.80989516e-02  1.36760145e-01 -8.85324329e-02\n",
      " -3.73041779e-02  2.15636976e-02 -4.47025821e-02 -5.27586117e-02\n",
      "  2.42676176e-02  7.18019977e-02  8.01976025e-02  2.13183407e-02\n",
      " -2.48050634e-02  7.30048353e-03 -2.13495493e-02  4.77770679e-02\n",
      "  1.46226272e-01 -3.72944027e-02  6.04705624e-02 -9.60162561e-03] \n",
      " (384,)\n"
     ]
    }
   ],
   "source": [
    "# sentence embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model=SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "vec=model.encode('best movie ever')\n",
    "\n",
    "print(vec, '\\n', vec.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
